[
  {
    "id": 37,
    "name": "线性回归 (Linear Regression)",
    "title": "我多花一块钱广告，能多赚几块钱？",
    "description": "想象在散乱的数据点中，你想找到一条“最合身”的直线，来概括它们的整体趋势。线性回归就是帮你画出这条线的工具。它揭示了“你投入的X”（比如广告费）和“你得到的Y”（比如新客数）之间最简单的关系：X增加1，Y会增加多少？",
    "parameters": "β0 (截距), β1 (斜率)",
    "formula": "Y = β0 + β1*X + ε",
    "application": [
      "预测下个月投入10万元广告费，大概能带来多少新客户。",
      "分析医生经验年限与手术满意度评分之间的关系。",
      "评估项目定价与购买意愿之间的关联。"
    ],
    "takeaway": "将“感觉”量化为“数据”，为预算分配和绩效评估提供最直接的数学依据。让你清楚地知道，多投入一分资源，能换来几分回报。",
    "group": 4,
    "relatedModels": [
      {
        "id": 38,
        "name": "逻辑回归",
        "reason": "逻辑回归是线性回归在分类问题上的延伸，用于预测概率而非连续值。"
      },
      {
        "id": 39,
        "name": "随机森林",
        "reason": "当变量关系不是简单的线性时，随机森林作为一种非线性模型，能提供更准确的回归预测。"
      },
      {
        "id": 29,
        "name": "多变量正态分布",
        "reason": "线性回归的许多统计推断（如置信区间）都基于其误差项服从正态分布的假设。"
      }
    ]
  },
  {
    "id": 38,
    "name": "逻辑回归 (Logistic Regression)",
    "title": "客户会不会买？猜一下概率",
    "description": "这是专门用来做“是/否”预测的工具。它不像线性回归那样预测一个数值，而是预测一个概率。比如，根据客户的种种特征，它不会直接说“这个客户会买”，而是会告诉你“这个客户有70%的可能会买”。",
    "parameters": "β0, β1, ... (回归系数)",
    "formula": "P(Y=1) = 1 / (1 + e^-(β0 + β1X1 + ...))",
    "application": [
      "根据客户的年龄、过往消费记录，预测其购买一个新项目的概率有多大。",
      "判断一个超过3个月未到店的客户，有多大概率会彻底流失。",
      "评估一个新线索的质量，预测其最终成交的可能性。"
    ],
    "takeaway": "从“被动等待结果”到“主动预测概率”。它让你在客户做出最终决定之前，就能识别机会和风险，并采取针对性的干预措施。",
    "group": 4,
    "relatedModels": [
      {
        "id": 37,
        "name": "线性回归",
        "reason": "逻辑回归是广义线性模型的一种，与线性回归在理论上一脉相承。"
      },
      {
        "id": 49,
        "name": "支持向量机",
        "reason": "SVM是另一种强大的分类算法，特别是在处理高维和非线性数据时，可与逻辑回归进行效果对比。"
      },
      {
        "id": 42,
        "name": "朴素贝叶斯分类器",
        "reason": "作为一种生成模型，朴素贝叶斯为分类问题提供了与逻辑回归（判别模型）不同的解决思路。"
      }
    ]
  },
  {
    "id": 39,
    "name": "随机森林 (Random Forest)",
    "title": "三个臭皮匠，顶个诸葛亮",
    "description": "如果一棵决策树是一个普通的“臭皮匠”，那随机森林就是成百上千个“臭皮匠”组成的智囊团。每个“皮匠”都看一部分信息，给出自己的判断，最后大家投票决定。这种“集体智慧”模式，让它的预测通常比任何单个模型都更准、更稳。",
    "parameters": "不适用 (集成算法)",
    "formula": "不适用 (集成算法)",
    "application": [
      "综合几十个客户特征（年龄、消费频率、浏览行为等）来预测其未来一年的消费总额（LTV）。",
      "在众多影响因素中，找出对客户满意度影响最大的前5个因素。",
      "构建一个比单一逻辑回归更精准的客户流失预警模型。"
    ],
    "takeaway": "超越简单的线性思维，帮你找到驱动业务增长的核心杠杆。当你不确定哪些因素是关键时，随机森林能帮你拨开迷雾，看清真相。",
    "group": 4,
    "relatedModels": [
      {
        "id": 49,
        "name": "支持向量机",
        "reason": "SVM是与随机森林齐名的高性能分类/回归算法，在实际项目中经常作为对比模型。"
      },
      {
        "id": 50,
        "name": "增益模型",
        "reason": "随机森林的变体（如Causal Forest）是实现增益模型的常用技术之一，用于估计干预措施的个性化效果。"
      },
      {
        "id": 48,
        "name": "主成分分析",
        "reason": "随机森林的特征重要性排序，可以为后续使用PCA进行数据降维提供指导。"
      }
    ]
  },
  {
    "id": 40,
    "name": "K-均值聚类 (K-Means)",
    "title": "物以类聚，客户也一样",
    "description": "想象你面前有一大堆混杂的豆子（红豆、绿豆、黄豆），K-均值聚类就像一个神奇的筛子，你告诉它要分成几堆（K=3），它就能自动把特征最像的豆子聚在一起。在商业上，它能帮你把客户自动分成不同群组，而你甚至事先都不知道该怎么分。",
    "parameters": "K (簇的数量)",
    "formula": "不适用 (聚类算法)",
    "application": [
      "根据消费行为，将客户自动分为“高价值潜力股”、“价格敏感型”、“项目尝鲜者”、“忠诚老客”等群体。",
      "为不同城市的分店进行客户画像，制定本地化的运营策略。",
      "发现隐藏的客户群体，找到新的市场机会。"
    ],
    "takeaway": "让你发现那些凭经验无法洞察的客户分群方式，是实现“千人千面”精准营销和个性化服务的数据基础。",
    "group": 4,
    "relatedModels": [
      {
        "id": 36,
        "name": "RFM模型",
        "reason": "RFM是基于经验规则的聚类方法，而K-Means是基于算法的聚类方法，两者可以相互验证和补充。"
      },
      {
        "id": 48,
        "name": "主成分分析",
        "reason": "PCA常作为K-Means的预处理步骤，通过降维和去相关性，可以有效提升聚类效果和可视化能力。"
      }
    ]
  },
  {
    "id": 41,
    "name": "时间序列预测 (ARIMA)",
    "title": "听懂数据的心跳和呼吸",
    "description": "你的销售数据不是一堆随机数字，它有自己的“心跳”（季节性波动）和“呼吸”（长期趋势）。时间序列模型就像一位经验丰富的老中医，通过“号脉”，它能摸清你业务数据内在的节律，并据此预测它未来的走向。",
    "parameters": "p, d, q (AR, I, MA 阶数)",
    "formula": "不适用 (时间序列模型)",
    "application": [
      "精准预测未来三个月的每月营收，为财务规划提供依据。",
      "预测下一个长假（如国庆、春节）的客户到店量，提前优化人员排班和物资储备。",
      "分析市场活动的长期效果，是短期脉冲还是带来了持续增长。"
    ],
    "takeaway": "让你的商业规划不再是“拍脑袋”，而是基于数据自身的节奏和规律。它帮助你从容应对业务的波峰波谷，抓住增长机会，规避潜在风险。",
    "group": 4,
    "relatedModels": [
      {
        "id": 30,
        "name": "马尔可夫链",
        "reason": "两者都用于分析序列数据，但ARIMA关注连续数值的演变，而马尔可夫链关注离散状态之间的转移。"
      },
      {
        "id": 37,
        "name": "线性回归",
        "reason": "最简单的时间序列模型就是以时间为自变量的线性回归，ARIMA是其更复杂的演进版本。"
      },
      {
        "id": 3,
        "name": "泊松分布",
        "reason": "对于以“计数”为单位的时间序列（如每小时到店人数），基于泊松分布的整数时间序列模型是更精确的选择。"
      }
    ]
  },
  {
    "id": 42,
    "name": "朴素贝叶斯分类器 (Naive Bayes)",
    "title": "给客户贴标签，AI如何“猜”得准？",
    "description": "想象一位医生根据病人的多种症状（如发烧、咳嗽）来诊断疾病。朴素贝叶斯就像这位医生，但更擅长处理数据。它基于一个“朴素”的假设：各个症状（特征）之间是相互独立的。尽管这个假设在现实中不总成立，但它极其高效，尤其擅长处理文本分类、垃圾邮件过滤等任务。在医美行业，它能根据客户的零散信息，快速“猜”出她属于哪个群体。",
    "parameters": "不适用 (分类算法)",
    "formula": "P(A|B) = (P(B|A) * P(A)) / P(B)",
    "application": [
      "根据客户在咨询时提到的关键词（如“价格”、“安全”、“效果”），自动将其分类为“价格敏感型”、“安全导向型”或“效果至上型”。",
      "分析用户评论的情感倾向，自动识别出正面、负面或中性评价。",
      "根据客户的人口统计学特征和过往消费记录，预测她是否会对某个新项目感兴趣。"
    ],
    "takeaway": "这是实现客户自动化、规模化打标签的利器。它能让你从海量非结构化数据（如聊天记录、评论）中快速提取洞察，极大提升了营销的精准度和客服的效率。",
    "group": 4,
    "relatedModels": [
      {
        "id": 35,
        "name": "思维框架：贝叶斯推断",
        "reason": "朴素贝叶斯分类器是贝叶斯定理最直接、最广泛的应用之一。"
      },
      {
        "id": 38,
        "name": "逻辑回归",
        "reason": "两者都是经典的分类算法，朴素贝叶斯是生成模型，逻辑回归是判别模型，对比学习有助于加深理解。"
      },
      {
        "id": 14,
        "name": "多项分布",
        "reason": "在文本分类任务中，多项式朴素贝叶斯模型被广泛使用，它假设特征（如单词计数）服从多项分布。"
      }
    ]
  },
  {
    "id": 48,
    "name": "主成分分析 (PCA)",
    "title": "50个问题，如何总结成3个重点？",
    "description": "想象你有一份包含50个问题的客户满意度问卷，变量太多，看得眼花缭乱。PCA（主成分分析）就像一个超级压缩工具，它能帮你把这50个相互关联的变量，“压缩”成少数几个互不相关的新变量（主成分），同时保留绝大部分原始信息。比如，最后可能发现这50个问题其实主要反映了“服务质量”、“价格感知”和“效果预期”这三大核心维度。",
    "parameters": "不适用 (降维技术)",
    "formula": "不适用 (降维技术)",
    "application": [
      "客户满意度问卷分析：将几十个细分问题降维，找到影响满意度的最核心的几个因素。",
      "客户分群预处理：在进行K-均值聚类前，先用PCA处理大量客户特征，可以提升聚类的效果和稳定性。",
      "构建综合评分模型：将多个相关的绩效指标（如客单价、复购率、满意度）合成为一个综合的“客户价值分”。",
      "数据可视化：将高维数据降到二维或三维，以便在图表上直观地展示客户群体的分布和关系。"
    ],
    "takeaway": "数据不是越多越好，关键是抓住主要矛盾。PCA帮你拨开数据迷雾，洞察复杂现象背后的核心驱动力，让你的分析更聚焦、更深刻。",
    "group": 4,
    "relatedModels": [
      {
        "id": 40,
        "name": "K-均值聚类",
        "reason": "PCA是K-均值聚类等无监督学习算法的常用“预处理器”，通过降维可以改善聚类效果。"
      },
      {
        "id": 29,
        "name": "多变量正态分布",
        "reason": "PCA处理的是多个相关变量，这正是多变量正态分布所描述的数据结构。"
      }
    ]
  },
  {
    "id": 49,
    "name": "支持向量机 (SVM)",
    "title": "如何画一条线，完美区分VIP和普通客户？",
    "description": "想象在一个二维图上，散布着VIP客户和普通客户的数据点。SVM（支持向量机）的目标，就是找到一条“最宽的街道”来把这两群客户分开，确保街道的边界（决策边界）离最近的客户点（支持向量）尽可能远。这种“留有余地”的分隔方式，使得它在处理复杂、高维分类问题时非常强大和稳健。",
    "parameters": "不适用 (分类算法)",
    "formula": "不适用 (分类算法)",
    "application": [
      "高精度客户流失预测：相比逻辑回归，SVM在处理多维度、非线性客户行为数据时，往往能达到更高的预测准确率。",
      "图像识别：用于皮肤检测（如识别色斑、痤瘡）或人脸识别等，区分不同特征的图像。",
      "文本分类：自动将客户反馈分为正面、负面或建议，其效果通常优于朴素贝叶斯。",
      "生物信息学：在基因数据分析等高维场景中有广泛应用。"
    ],
    "takeaway": "当你的分类问题（如流失预测）特征非常多、关系非常复杂时，SVM是一个值得尝试的“重武器”。它追求的不仅是“分开”，更是“漂亮地分开”。",
    "group": 4,
    "relatedModels": [
      {
        "id": 38,
        "name": "逻辑回归",
        "reason": "两者都是强大的分类模型，但SVM在处理非线性和高维数据时通常表现更优。"
      },
      {
        "id": 39,
        "name": "随机森林",
        "reason": "SVM和随机森林是两种不同思路的顶级分类算法，在实践中常常将两者进行效果对比。"
      }
    ]
  }
]